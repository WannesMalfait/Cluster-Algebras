\documentclass{article}

\usepackage{vub}
\input{definitions/preamble}
\input{definitions/macros}
\input{definitions/letterfonts}

\usetikzlibrary{shapes.geometric,calc, decorations.pathmorphing}

\newcommand{\ex}{\mathbf{ex}}
\newcommand{\frz}{\mathbf{frz}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\tbx}{\tilde{\bx}}
\newcommand{\tB}{\tilde{B}}
\DeclareMathOperator{\Fract}{Fract}
\DeclareMathOperator{\id}{id}

%%%%%%%%%%%%%
%% Fill in!%%
%%%%%%%%%%%%%
\title{Cluster Algebras}
\subtitle{Collection of notes on (quantum) cluster algebras}
\faculty{Sciences and Bio-Engineering Sciences}
\author{Wannes Malfait}
\date{Academic year 2023-2024}
\promotors{Kenny De Commer, Geoffrey Janssens}
% \pretitle{Dissertation for the grade of Master's in mathematics}

\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage

\section{Classical cluster algebras}

Mostly use \cite{FominWilliams2021IntroductionCA_1-3} as reference together with
Geoffrey's notes.

\subsection{Combinatorial integer sequences}

In this section we will look at some integer sequences coming from number theory or
combinatorial data, and observe some interesting patterns. In the next section we will
see how these can all be viewed as special instances of a much more general framework.

Let us start with the simplest of the sequences.
\begin{definition}
	Let $a_n$ be the sequence defined through the recursion relation
	\begin{equation}
		\label{eq:somos_4}
		a_{n+4} = \frac{a_{n+3}a_{n+1}+ a_{n+2}^2}{a_n}
	\end{equation}
	with initial conditions $a_0 = a_1 = a_2 = a_3 = 1$. This sequence is known as the \emph{Somos-4}\index{Somos-4 sequence} sequence, named after its inventor, Michael Somos.
\end{definition}
Computing the first few terms of the sequence, we find:
\begin{align*}
	a_4    & = \frac{1 \cdot 1 + 1^2}{1} = 2                                           \\
	a_5    & = \frac{2 \cdot 1 + 1^2}{1} = 3                                           \\
	a_6    & = \frac{3 \cdot 1 + 2^2}{1} = 7                                           \\
	a_7    & = \frac{7 \cdot 2 + 3^2}{2} = 23                                          \\
	a_8    & = \frac{23 \cdot 3 + 7^2}{2} = \frac{118}{2} = 59                         \\
	a_9    & = \frac{59 \cdot 7 + 23^2}{3} = \frac{942}{3} = 314                       \\
	a_{10} & = \frac{314 \cdot 23 + 59^2}{7} = \frac{10703}{7} = 1529                  \\
	a_{11} & = \frac{1529 \cdot 59 + 314^2}{23} = \frac{188807}{23} = 8209             \\
	a_{12} & = \frac{8209 \cdot 314 + 1529^2}{59} = \frac{4915467}{59} = 83313         \\
	a_{13} & = \frac{83313 \cdot 1529 + 8209^2}{314} = \frac{194773258}{314} = 620297.
\end{align*}
From the definition of the sequence, there is no reason, a priori, to assume that all its elements would be integers. However, somewhat remarkably, the denominators seem to always cancel out perfectly. In the next section we will prove that all the terms in the sequence are indeed integers,
as a corollary of the \emph{Laurent phenomenon}\index{Laurent!-phenomenon}.

The next family of integer sequences comes from \emph{$\SL_2(\bbZ)$-frieze
	patterns}\footnote{The name ``frieze pattern'' comes from architecture, where it refers
	to a horizontal strip, often found just below the roofline, which is decorated with
	patterns.}\index{frieze pattern}. The idea of a frieze pattern is best explained
through an example (\cite{Coxeter1971FriezePatterns}). Take for example the following
pattern:
\begin{equation*}
	\dots\quad
	\begin{tikzcd}[
			sep = 0.2em, cramped,
		]
		&0&&0&&0&&0&&0&&0&&0&&0&&0&&0&&0\\
		1&&1&&1&&1&&1&&1&&1&&1&&1&&1&&1\\
		&1&&2&&2&&3&&1&&2&&4&&1&&2&&2&&3\\
		3&&1&&3&&5&&2&&1&&7&&3&&1&&3&&5\\
		&2&&1&&7&&3&&1&&3&&5&&2&&1&&7&&3\\
		4&&1&&2&&4&&1&&2&&2&&3&&1&&2&&4\\
		&1&&1&&1&&1&&1&&1&&1&&1&&1&&1&&1\\
		0&&0&&0&&0&&0&&0&&0&&0&&0&&0&&0
	\end{tikzcd}
	\quad
	\dots
\end{equation*}
The defining property is that the $2 \times 2$ diamonds
\begin{equation*}
	\begin{matrix}
		  & b &   \\
		a &   & d \\
		  & c &
	\end{matrix}
\end{equation*}
formed by adjacent elements, can be seen as an element of $\SL_2 (\bbZ)$, i.e., $ad - bc = 1$. Other than the bounding rows of ones and zeros, there is no additional requirement. In what follows we will omit the irrelevant row of zeros. One could ask if it is always possible to construct such a pattern for any number of rows. If so, one might be interested in knowing how many such patterns there are. Furthermore, one might notice that the pattern is periodic, repeating every 7 columns. In fact, the pattern even has ``half-periodicity'' where the marked triangle undergoes a translation and reflection.
\begin{equation*}
	\dots\quad
	\begin{tikzcd}[
			sep = 0.2em, cramped,
			execute at end picture = {
					\draw[blue, dashed, rounded corners]
					($(\tikzcdmatrixname-1-1.north west) + (-0.3, 0.05)$) -- ($(\tikzcdmatrixname-1-11.north east)+ (0.3, 0.05)$)--($(\tikzcdmatrixname-6-6.south) + (0,-0.05)$) -- cycle;
					\draw[red, dashed, rounded corners]
					($(\tikzcdmatrixname-6-8.south west) + (-0.3, -0.05)$) -- ($(\tikzcdmatrixname-6-18.south east)+ (0.3, -0.05)$)--($(\tikzcdmatrixname-1-13.north) + (0,0.05)$) -- cycle;
				}
		]
		1&&1&&1&&1&&1&&1&&1&&1&&1&&1&&1\\
		&1&&2&&2&&3&&1&&2&&4&&1&&2&&2&&3\\
		3&&1&&3&&5&&2&&1&&7&&3&&1&&3&&5\\
		&2&&1&&7&&3&&1&&3&&5&&2&&1&&7&&3\\
		4&&1&&2&&4&&1&&2&&2&&3&&1&&2&&4\\
		&1&&1&&1&&1&&1&&1&&1&&1&&1&&1&&1\\
	\end{tikzcd}
	\quad
	\dots
\end{equation*}

To make such a pattern, we start with the observation that the rest of the pattern is
completely determined by a lattice path from top to bottom. Indeed, using the
$\SL_2(\bbZ)$ rule, one can fill in the rest of the pattern. For example, say we
started with the following partially filled in pattern:
\begin{equation*}
	\dots\quad
	\begin{tikzcd}[
			sep = 0.2em, cramped,
		]
		1&&1&&1&&1&&1&&1&&1\\
		&a\\
		b\\
		&1&&1&&1&&1&&1&&1\\
	\end{tikzcd}
	\quad
	\dots
\end{equation*}
then we could fill out the rest as follows
\begin{equation*}
	\dots\quad
	\begin{tikzcd}[
			sep = 0.2em, cramped,
		]
		1&&1&&1&&1&&1&&1&&1\\
		&a&& \frac{1+a+b}{ab} && b && \frac{1+a}{b} && \frac{1+b}{a} && a\\
		b&& \frac{1+a}{b} &&  \frac{1+b}{a} && a && \frac{1+a+b}{ab} && b\\
		&1&&1&&1&&1&&1&&1\\
	\end{tikzcd}
	\quad
	\dots
\end{equation*}
Since all the denominators are monomials in $a$ and $b$, it follows that when $a = b = 1$, all the
elements will be integers, as required.

It seems that we somehow got lucky in this case. There is again, a priori, no reason to
assume that for any number of rows, we will always be able to choose the initial
integers such that all the fractions simplify. The fact that this is possible, follows
again from the ``Laurent phenomenon''\index{Laurent!-phenomenon}, on which we can now
shed a bit more light. Let $a_1, a_2, \dots, a_n$ be the initial integers chosen on the
lattice path. Then, in this context, the Laurent phenomenon states that all the other
elements of the frieze pattern can be written as Laurent
polynomials\index{Laurent!-polynomial} in $a_1 , \dots, a_n$ with coefficients in
$\bbZ$, i.e., as an element of $\bbZ [a_1 ^\pm, \dots, a_n^\pm]$. So, any lattice path
from top to bottom consisting of only ones, will yield a frieze pattern. This already
proves the existence of such frieze patterns for any number of rows. We will return to
the other questions in the next section.

Let us now look at a final example, coming from triangulations of $n$-gons. We first
recall the following theorem from Euclidean geometry.
\begin{theorem}[Ptolomy's Theorem]
	Let $A,B,C,D$ be distinct points on a circle, in cyclic order (\cref{fig:ptolomy}).
	These determine vertices of a quadrilateral, where the side, and diagonal lengths
	satisfy the following rule:
	\begin{equation*}
		|AC| \cdot |BD| = |AB|\cdot |CD| + |AD| \cdot |BC|.
	\end{equation*}
\end{theorem}

\begin{figure}
	\centering

	\begin{tikzpicture}
		\coordinate (center) at (0,0);
		\def\radius{2.5cm}
		\draw (center) circle[radius=\radius];

		% points on the circle
		\path (center) ++(-120:\radius) coordinate (A);
		\path (center) ++(-30:\radius) coordinate (B);
		\path (center) ++(40:\radius) coordinate (C);
		\path (center) ++(150:\radius) coordinate (D);

		\begin{scriptsize}
			% Chords
			\draw[color=red, line width=1pt] (A) -- node[left] {$AD$} (D);
			\draw[color=red, line width=1pt] (B) -- node[left] {$BC$} (C);
			\draw[color=blue, line width=1pt] (A) -- node[above] {$AB$} (B);
			\draw[color=blue, line width=1pt] (D) -- node[above] {$DC$} (C);
			\draw[color=violet, line width=1pt] (A) -- node[above=8pt, near start] {$AC$} (C);
			\draw[color=violet, line width=1pt] (D) -- node[above=2pt, near start] {$BD$} (B);

			% Draw the points over the chords
			\fill[black] (A) circle[radius=2pt] ++(-120:1em) node {$A$};
			\fill[black] (B) circle[radius=2pt] ++(-30:1em) node {$B$};
			\fill[black] (C) circle[radius=2pt] ++(40:1em) node {$C$};
			\fill[black] (D) circle[radius=2pt] ++(150:1em) node {$D$};

		\end{scriptsize}
	\end{tikzpicture}
	\caption{Ptolomy's theorem:
	${\color{violet} |AC| \cdot |BD|}
		= {\color{red} |AD|\cdot |BC|} + {\color{blue} |AB| \cdot |CD|}$.}
	\label{fig:ptolomy}
\end{figure}

This rule allows to compute the length of one of the diagonals in terms of the other,
given the side lengths. We will now apply this to triangulations of polygons.

Let $1, 2, \dots, n$ denote $n$ points on a circle, arranged in cyclic order. By
connecting these points through sides $P_{i, i+1}$, where the indices are taken modulo
$n$, we obtain a polygon with $n$-sides. A triangulation\index{triangulations!of
	polygons}, $T$, is a choice of $(n-3)$ non-crossing diagonals. This results in a
partitioning of the polygon in $n-2$ triangles. We will see triangulations in much more
detail in a later section, and will therefore keep things brief here. For now, it is
enough to understand things visually (cf. \cref{fig:triangulations}).

\begin{figure}
	\centering

	\begin{tikzpicture}
		\node[name=h, shape=regular polygon, draw, regular polygon sides = 6, minimum size = 3cm]{};
		\draw[] (h.corner 1) -- (h.corner 3);
		\draw[] (h.corner 1) -- (h.corner 4);
		\draw[] (h.corner 1) -- (h.corner 5);
	\end{tikzpicture}
	\begin{tikzpicture}
		\node[name=h, shape=regular polygon, draw, regular polygon sides = 6, minimum size = 3cm]{};
		\draw[] (h.corner 2) -- (h.corner 5);
		\draw[] (h.corner 2) -- (h.corner 4);
		\draw[] (h.corner 1) -- (h.corner 5);
	\end{tikzpicture}
	\begin{tikzpicture}
		\node[name=h, shape=regular polygon, draw, regular polygon sides = 6, minimum size = 3cm]{};
		\draw[] (h.corner 1) -- (h.corner 3);
		\draw[] (h.corner 3) -- (h.corner 5);
		\draw[] (h.corner 1) -- (h.corner 5);
	\end{tikzpicture}

	\caption{Some triangulations of a hexagon.}
	\label{fig:triangulations}
\end{figure}

Starting from a triangulation, $T$, we obtain a new triangulation, $T'$, by
``flipping'' a diagonal. Any diagonal in a triangulation lies on precisely 2 triangles.
These two triangles form a quadrilateral. To flip the diagonal, you replace it with the
other diagonal of that quadrilateral. Again, this is most easily seen visually:
\begin{equation*}
	\begin{tikzpicture}[baseline]
		\node[name=h, shape=regular polygon, draw, regular polygon sides = 6, minimum size = 2cm]{};
		\draw[] (h.corner 1) -- (h.corner 3);
		\draw[dashed] (h.corner 1) -- (h.corner 4);
		\draw[] (h.corner 1) -- (h.corner 5);
	\end{tikzpicture}
	\quad \leadsto \quad
	\begin{tikzpicture}[baseline]
		\node[name=h, shape=regular polygon, draw, regular polygon sides = 6, minimum size = 2cm]{};
		\draw[] (h.corner 1) -- (h.corner 3);
		\draw[dashed] (h.corner 3) -- (h.corner 5);
		\draw[] (h.corner 1) -- (h.corner 5);
	\end{tikzpicture}
\end{equation*}
%
Now, using Ptolomy's theorem, the length of the new diagonal can be computed given that
we knew the lengths of all the edges in the previous triangulation. We now ignore
Euclidean geometry, and just use Ptolomy's theorem as a recurrence relation to
construct a collection of numbers as follows: Pick a triangulation and set all the edge
lengths equal to one. Then at each step, choose a diagonal in the triangulation and
flip it. Compute its edge length using Ptolomy's theorem. This is the next number in
the collection. For example, we could obtain a sequence starting like this (we omit the
ones on the sides):
\begin{equation*}
	\begin{tikzpicture}[baseline]
		\node[name=h, shape=regular polygon, draw, regular polygon sides = 6, minimum size = 1.5cm]{};
		\draw[] (h.corner 1) -- node[fill=white, font=\footnotesize] {1} (h.corner 3);
		\draw[] (h.corner 1) -- node[fill=white, font=\footnotesize] {1} (h.corner 4);
		\draw[] (h.corner 1) -- node[fill=white, font=\footnotesize] {1} (h.corner 5);
	\end{tikzpicture}
	\leadsto
	\begin{tikzpicture}[baseline]
		\node[name=h, shape=regular polygon, draw, regular polygon sides = 6, minimum size = 1.5cm]{};
		\draw[] (h.corner 1) -- node[fill=white, font=\footnotesize] {1} (h.corner 3);
		\draw[dashed] (h.corner 3) -- node[fill=white, font=\footnotesize] {2} (h.corner 5);
		\draw[] (h.corner 1) -- node[fill=white, font=\footnotesize] {1} (h.corner 5);
	\end{tikzpicture}
	\leadsto
	\begin{tikzpicture}[baseline]
		\node[name=h, shape=regular polygon, draw, regular polygon sides = 6, minimum size = 1.5cm]{};
		\draw[dashed] (h.corner 2) -- node[fill=white, font=\footnotesize] {3} (h.corner 5);
		\draw[] (h.corner 3) -- node[fill=white, font=\footnotesize] {2} (h.corner 5);
		\draw[] (h.corner 1) -- node[fill=white, font=\footnotesize] {1} (h.corner 5);
	\end{tikzpicture}
	\leadsto
	\begin{tikzpicture}[baseline]
		\node[name=h, shape=regular polygon, draw, regular polygon sides = 6, minimum size = 1.5cm]{};
		\draw[] (h.corner 2) -- node[fill=white, font=\footnotesize] {3} (h.corner 5);
		\draw[] (h.corner 3) -- node[fill=white, font=\footnotesize] {2} (h.corner 5);
		\draw[dashed] (h.corner 2) -- node[fill=white, font=\footnotesize] {4} (h.corner 6);
	\end{tikzpicture}
	\leadsto
	\begin{tikzpicture}[baseline]
		\node[name=h, shape=regular polygon, draw, regular polygon sides = 6, minimum size = 1.5cm]{};
		\draw[dashed] (h.corner 3) -- node[fill=white, font=\footnotesize] {3} (h.corner 6);
		\draw[] (h.corner 3) -- node[fill=white, font=\footnotesize] {2} (h.corner 5);
		\draw[] (h.corner 2) -- node[fill=white, font=\footnotesize] {4} (h.corner 6);
	\end{tikzpicture}
	\leadsto
	\begin{tikzpicture}[baseline]
		\node[name=h, shape=regular polygon, draw, regular polygon sides = 6, minimum size = 1.5cm]{};
		\draw[] (h.corner 3) -- node[fill=white, font=\footnotesize] {3} (h.corner 6);
		\draw[] (h.corner 3) -- node[fill=white, font=\footnotesize] {2} (h.corner 5);
		\draw[dashed] (h.corner 3) -- node[fill=white, font=\footnotesize] {1} (h.corner 1);
	\end{tikzpicture}
	\leadsto \cdots
\end{equation*}
%
Once again, we observe that we only obtain integers. Furthermore, there seems to be a
limit to which integers we can obtain this way. This hints at a hidden periodicity. The
Laurent phenomenon offers an explanation for why we only obtain integers: the lengths
of the diagonals are Laurent polynomials in the originally chosen lengths.

There are many more examples like the three that we just gave. One can look at wiring
diagrams, generalized Somos sequences, Markov Triples, knight recurrence, the
Gale-Robinson sequence, etc. As the focus of this thesis is not on number theory, we
refrain from delving deeper into this interesting world. We refer interested readers to
\cite[Chapter 3.4]{FominWilliams2021IntroductionCA_1-3} and
\cite{FominZelevinsky2002Laurent}.

\subsection{Quivers and mutations}

As observed in the previous section, the examples share some common features. The most
prominent of these was the Laurent phenomenon. There are some more subtle similarities,
which will become clear in this section. The main role will be played by quivers, and
their mutations.

\begin{definition}[Quivers]
	A \emph{quiver}\index{quiver} is a finite directed (multi)-graph with no 1-cycles (vertex connected to itself) or 2-cycles (two vertices connected by a pair of opposite arrows) (cf. \cref{fig:triangulations}).
\end{definition}

\begin{figure}
	\centering
	\begin{equation*}
		\begin{tikzcd}
			&\bullet \arrow[loop] \arrow[r] &\bullet \\
			\bullet \rar & \bullet \arrow[r, bend left] & \bullet \arrow[l, bend left]
		\end{tikzcd}
		\hspace{2cm}
		\begin{tikzcd}[row sep=small]
			&&& \bullet \\
			\bullet \ar[rrrd, bend right]\rar &\bullet  \rar[leftarrow] &\bullet \ar[ru, shift left] \ar[ru, shift right] \ar[rd] \\
			&&& \bullet\\
			\\
			\bullet \ar[rr] && \bullet \ar[ld]\\
			& \bullet \ar[lu]
		\end{tikzcd}
	\end{equation*}
	\caption{The graphs on the left are not quivers, the graphs on the right are.}
	\label{fig:quivers}
\end{figure}

We will now fix some notation for what follows. Write $[a,b] = \{a, a + 1, \dots, b\}$
for integers $a,b \in \bbZ$, where $[a,b] = \emptyset$ if $a > b$. Now, fix an integer
$N$, and a subset $\ex subset.eq [1, N]$ of size $n$. The elements of $\ex$ will be
called \emph{exchangeable}\index{exchangeable}, while the elements of $\frz = [1, N]
	\setminus \ex$ will be called \emph{frozen}\index{frozen}. Finally, let $\mcF = \bbQ
	(X_1, \dots, X_N)$ be the field of rational functions over $\bbQ$, in $N$ variables.

\begin{definition}
	We call a pair $(Q, \tbx)$ a \emph{seed}\index{seed} if
	\begin{enumerate}
		\item $Q$ is a quiver with vertices $Q_0 = [1, N]$.
		\item $\tbx = \{x_1, \dots, x_N\}$ is a \emph{free generating set} of $\mcF$. That is, $\tbx$ is a set of $N$ algebraically independent elements that generate $\mcF$.
	\end{enumerate}
	The set $\bx = \{x_i \mid i \in \ex\} \subseteq \tbx$ will be referred to as the \emph{cluster}\index{cluster}. The elements of $\bx$ will be called \emph{cluster variables}\index{cluster!-variables}.
\end{definition}

Although not strictly necessary, we will assume that the quiver $Q$ contains no arrows
between the frozen vertices, i.e., the vertices in $Q_0 \cap \frz$. Arrows between
exchangeable and frozen vertices are allowed. When drawing a quiver, the frozen
vertices will be drawn with a box, while the exchangeable vertices will just be drawn
normally.

Given a seed, we can convert it to another seed through a \emph{seed
	mutation}\index{seed!-mutation}.
\begin{definition}
	Let $k \in \ex$ be an exchangeable vertex of the quiver $Q$.
	We define the \emph{mutation in direction $k$} of the seed
	$(Q, \tbx)$ to be the seed $\mu_k(Q, \tbx) = (Q', \tbx')$, where
	\begin{enumerate}
		\item $Q'_0 = Q_0$.
		\item For every pair of vertices $i,j$ with $s$ arrows $i \to k$ and $t$ arrows $k \to j$ we
		      ``collapse'' these arrows into $s\cdot t$ arrows $i \to j$, cancelling pairwise with
		      any arrows $j \to i$.
		      \begin{equation*}
			      \begin{tikzcd}[column sep=small]
				      i \ar[rr, "r"] \ar[rd, "s"] && j \\
				      & k \ar[ur, "t"]
			      \end{tikzcd}
			      \quad \begin{tikzcd}
				      \; \rar[rightsquigarrow, "\mu_k"]& \;
			      \end{tikzcd}\quad
			      \begin{tikzcd}[column sep=small]
				      i \ar[rr, "r + st"] \ar[rd,leftarrow, "s"] && j \\
				      & k \ar[ur, leftarrow, "t"]
			      \end{tikzcd}
		      \end{equation*}
		      Here we take $r$ to be negative, if the arrows actually point the other way.
		      If $i,j$ are both frozen, then we ignore this step.
		\item All arrows in $Q$ incident to $k$ get their orientation flipped.
		\item $\tbx' = \{x_1', \dots, x_n'\}$, where $x_i' = x_i$ for $i \neq k$, and $x'_k$
		      is given by the \emph{exchange relation}\index{exchange relation}
		      \begin{equation*}
			      x'_k = \frac{1}{x_k} \left(\prod_{i \to k} x_i + \prod_{k \to j} x_j\right),
		      \end{equation*}
		      where we take the product equal to 1 if $\{i \to k\} = \emptyset$ or $\{k \to j\} = \emptyset$.
	\end{enumerate}
\end{definition}

Before we give some examples, we prove a small lemma, which will also be useful for the
examples.
\begin{lemma}\label{lem:mutation_involution}
	Seed mutation at a fixed vertex is an involution, i.e., $\mu_k \circ \mu_k = id$.
\end{lemma}

\begin{proof}
	We first show that the quiver remains unchanged. For arrows incident to $k$, the
	mutation reverses the orientation. So, applying it twice yields the same orientation.
	Now, the only other part of the quiver that changes is at pairs of vertices $i,j$ with
	$s$ arrows $i \to k$ and $t$ arrows $k \to j$. Applying a single mutation introduces
	$s\cdot t$ new arrows $i \to j$. When applying the mutation the second time, we now
	have $s$ arrows $k \to i$ and $t$ arrows $j \to k$, due to the orientation flip of the
	arrows incident to $k$. Consequently, the mutation introduces $s \cdot t$ arrows $j \to
		i$ which cancel out exactly the arrows from the first mutation.

	To see that the cluster variables remain unchanged is a simple calculation:
	\begin{align*}
		x_k''
		 & = \frac{1}{x_k'}\left(\prod_{k \to i}x_i' + \prod_{j \to k} x_j'\right)                                                \\
		 & = x_k \left(\prod_{i \to k} x_i + \prod_{k \to j}x_j\right)^{-1} \left(\prod_{k \to i}x_i + \prod_{j \to k} x_j\right) \\
		 & = x_k,
	\end{align*}
	where we use that the exchange rule is unchanged by an orientation flip of all the arrows.
\end{proof}

We begin with an example to illustrate the mutation of the quiver.
\begin{example}
	We mutate the given quiver at vertex 2:
	\begin{equation*}
		\begin{tikzcd}
			& 4 \dlar \rar & 6 \dar \\
			1 \rar & 2 \uar \rar \dar[shift left] \dar [shift right] & 5 \\
			& 3 \ular
		\end{tikzcd}
		\begin{tikzcd}
			\; \rar[rightsquigarrow, "\mu_2"] &\;
		\end{tikzcd}
		\begin{tikzcd}
			& 4 \rar \dar & 6 \dar \\
			1  \drar \ar[rr,controls = {+(1, -2) and +(-1, -2)}] & 2 \lar & 5 \lar \\
			& 3 \uar[shift right] \uar[shift left]
		\end{tikzcd}
	\end{equation*}
	%
	The arrow $1 \to 2$ combined with the arrow $2 \to 4$ introduces one new arrow $1 \to
		4$ which cancels out the existing arrow $4 \to 1$. The arrow $1 \to 2$ combines with
	the 2 arrows $2 \to 3$ to create 2 new arrows $1 \to 3$,one of which cancels out with
	the existing arrow $3 \to 1$. Finally, the arrow $1 \to 2$ combined with the arrow $2
		\to 5$ yields an arrow $1 \to 5$. The arrows incident to the vertex 6 remain unchanged.
\end{example}

Let us now look at some examples, where we also keep track of the cluster variables.
\begin{example}
	The simplest example is the quiver consisting of a single vertex:
	\begin{equation*}
		Q = \begin{tikzcd}
			\bullet
		\end{tikzcd},
		\quad \bx = \{x\}.
	\end{equation*}
	%
	Mutating at the only vertex gives
	\begin{equation*}
		Q = \begin{tikzcd}
			\bullet
		\end{tikzcd},
		\quad \bx = \left\{\frac{x}{2}\right\}.
	\end{equation*}
	%
	If we mutate again, we end up with the original seed, as a consequence of
	\cref{lem:mutation_involution}. It is of course also straightforward to verify
	directly.
\end{example}
\begin{example}
	The next simplest example is the $A_2$ quiver:
	\begin{equation*}
		Q = \begin{tikzcd}
			1 \rar &2
		\end{tikzcd},
		\quad \bx = \left\{x_1, x_2\right\}.
	\end{equation*}
	%
	If we apply a mutation at the first vertex, we obtain:
	\begin{equation*}
		\mu_1(Q) = \begin{tikzcd}
			1 & \lar 2
		\end{tikzcd},
		\quad \mu_1(\bx) = \left\{\frac{1+x_2}{x_1}, x_2\right\}.
	\end{equation*}
	%
	We already know that mutating at the first vertex again will yield the same seed, so
	the only interesting thing to do is to see what happens after mutating at index 2:
	\begin{equation*}
		\mu_2(\mu_1(Q)) = \begin{tikzcd}
			1 \rar & 2
		\end{tikzcd},
		\quad  \mu_2(\mu_1(\bx)) = \left\{\frac{1+x_2}{x_1}, \frac{x_1 + x_2 + 1}{x_2}\right\}.
	\end{equation*}
	%
	Although we are back at the original quiver, the cluster variables are completely
	different. We now mutate again at the first vertex. We will use the notation
	$\mu_{k_1k_2\cdots k_l}$ as a shorthand for $\mu_{k_l} \circ \cdots \circ \mu_{k_2}
		\circ \mu_{k_1}$.
	\begin{equation*}
		\mu_{121}(Q) = \begin{tikzcd}
			1 &\lar 2
		\end{tikzcd},
		\quad  \mu_{121}(\bx) = \left\{\frac{x_1(x_1 x_2 + x_1 + x_2 + 1)}{x_1x_2(1+x_2)}, \frac{x_1 + x_2 + 1}{x_2}\right\}.
	\end{equation*}
	%
	The expression for the first cluster variable looks complicated, but can be
	dramatically simplified to $\frac{x_1 + 1}{x_2}$. We continue mutating:
	\begin{equation*}
		\mu_{1212}(Q) = \begin{tikzcd}
			1 \rar& 2
		\end{tikzcd},
		\quad  \mu_{1212}(\bx) = \left\{\frac{x_1 + 1}{x_2}, x_1\right\}.
	\end{equation*}
	%
	Once again, some simplification has taken place. We mutate a final time at the first
	vertex.
	\begin{equation*}
		\mu_{12121}(Q) = \begin{tikzcd}
			1 &\lar 2
		\end{tikzcd},
		\quad  \mu_{12121}(\bx) = \left\{x_2, x_1\right\}.
	\end{equation*}

	We have our original seed, except that the arrow in the quiver has been reversed, and
	that $x_1$ and $x_2$ have swapped places. In other words, after 5 mutations, the roles
	of 1 and 2 have swapped. It follows that another 5 swaps will give back the original
	seed. If one takes a close look at the obtained cluster variables, then we see that
	these correspond exactly to those that we found when trying to construct a frieze
	pattern with 2 rows. This is no coincidence, and we will come back to this later.
\end{example}
\begin{example}
	In this example, we look at the Markov quiver:
	\begin{equation*}
		\begin{tikzcd}[column sep= small]
			& 1 \ar[ld, shift left] \ar[ld, shift right]\\
			2 \ar[rr, shift left] \ar[rr, shift right] && 3 \ar[lu, shift left] \ar[lu, shift right]
		\end{tikzcd},
	\end{equation*}
	%
	which possesses the special property that it remains invariant under mutations at any
	vertex. Let us see what happens to the cluster variables as we mutate in a cyclic order
	of the vertices:
	\begin{align*}
		\bx            & = \{x, y, z\}                                                                                                                                                                               \\
		\mu_1(\bx)     & = \left\{\frac{y^2 + z^2}{x}, y, z\right\}                                                                                                                                                  \\
		\mu_{12}(\bx)  & = \left\{\frac{y^2 + z^2}{x}, \frac{y^4 + 2 z^2y^2 +z^4 + z^2x^2 }{x^2y}, z\right\}                                                                                                         \\
		\mu_{123}(\bx) & = \left\{\frac{y^2 + z^2}{x}, \frac{y^4 + 2 z^2y^2 +z^4 + z^2x^2 }{x^2y},\right.                                                                                                            \\
		               & \left. \frac{x^{4} z^{4} + x^{2} y^{6} + 4 x^{2} y^{4} z^{2} + 5 x^{2} y^{2} z^{4} + 2 x^{2} z^{6} + y^{8} + 4 y^{6} z^{2} + 6 y^{4} z^{4} + 4 y^{2} z^{6} + z^{8}}{x^{4} y^{2} z} \right\}
	\end{align*}
	%
	Mutating again at the first vertex gives the new cluster variable
	\begin{align*}
		 & \frac{x^{8} z^{6} + 4 x^{6} y^{4} z^{4} + 8 x^{6} y^{2} z^{6} + 4 x^{6} z^{8} + x^{4} y^{10} + 8 x^{4} y^{8} z^{2} + 24 x^{4} y^{6} z^{4} + 34 x^{4} y^{4} z^{6} + 23 x^{4} y^{2} z^{8}}{x^7y^4z^2} \\&+ \frac{6 x^{4} z^{10} + 2 x^{2} y^{12} + 14 x^{2} y^{10} z^{2} + 40 x^{2} y^{8} z^{4} + 60 x^{2} y^{6} z^{6} + 50 x^{2} y^{4} z^{8} + 22 x^{2} y^{2} z^{10} + 4 x^{2} z^{12}}{x^7 y^4 z^2}\\ &+ \frac{y^{14} + 7 y^{12} z^{2} + 21 y^{10} z^{4} + 35 y^{8} z^{6} + 35 y^{6} z^{8} + 21 y^{4} z^{10} + 7 y^{2} z^{12} + z^{14}}{x^{7} y^{4} z^{2}}.
	\end{align*}
	%
	Because the author doesn't want to spend too much time fiddling with alignment points
	to get long fractions to fit on a page, we will stop here. Mutating at vertex 2 would
	yield another fraction with 65 terms (with positive integer coefficients) in the
	numerator, and the expression $x^{12}y^7z^4$ in the denominator.
\end{example}

\begin{example}
	As a last example, we look at the $A_3$ quiver
	\begin{equation*}
		Q =
		\begin{tikzcd}
			1 \rar[] & 2 \rar[] &3
		\end{tikzcd},
		\quad \bx = \left\{x_1, x_2, x_3\right\}.
	\end{equation*}
	Mutation in direction 2 gives
	\begin{equation*}
		\mu_2(Q) =
		\begin{tikzcd}
			1 \rar[leftarrow] \ar[rr, bend right] & 2 \rar[leftarrow]& 3
		\end{tikzcd},
		\quad \mu_2(\bx) = \left\{x_1, \frac{x_1 + x_3}{x_2}, x_3\right\}.
	\end{equation*}
	If we instead apply a mutation in direction 1, we find
	\begin{equation*}
		\mu_1(Q) =
		\begin{tikzcd}
			1 \rar[leftarrow] & 2 \rar[]& 3
		\end{tikzcd},
		\quad \mu_1(\bx) = \left\{\frac{x_2 + 1}{x_1}, x_2, x_3\right\}.
	\end{equation*}
	Finally, a mutation in direction 3 would give
	\begin{equation*}
		\mu_3(Q) =
		\begin{tikzcd}
			1 \rar[] & 2 \rar[leftarrow]& 3
		\end{tikzcd},
		\quad \mu_3(\bx) = \left\{x_1, x_2, \frac{x_2 + 1}{x_3}\right\}.
	\end{equation*}
	Mutating in direction 1 on $\mu_2(Q)$ gives
	\begin{equation*}
		\mu_{21}(Q) =
		\begin{tikzcd}
			1 \rar[] \ar[rr,leftarrow, bend right] & 2 & 3
		\end{tikzcd},
		\quad \mu_{21}(\bx) = \left\{\frac{x_1 + x_3 + x_2x_3}{x_1x_2}, \frac{x_1 + x_3}{x_2}, x_3\right\}.
	\end{equation*}
	If we now mutate in direction 3, we obtain
	\begin{equation*}
		\mu_{213}(Q) =
		\begin{tikzcd}
			1 \rar[] \ar[rr, bend right] & 2 & 3
		\end{tikzcd},
		\quad \mu_{213}(\bx) = \left\{\frac{x_1 + x_3 + x_2x_3}{x_1x_2}, \frac{x_1 + x_3}{x_2}, \frac{x_1 x_2 + x_1 + x_3 + x_2 x_3}{x_1x_2x_3}\right\}.
	\end{equation*}
	It seems that the expressions keep getting messier and messier. We mutate again in direction 2:
	\begin{equation*}
		\mu_{2132}(Q) =
		\begin{tikzcd}
			1 \rar[leftarrow] \ar[rr, bend right] & 2 & 3
		\end{tikzcd},
	\end{equation*}
	\begin{equation*}
		\mu_{2132}(\bx)= \left\{\frac{x_1 + x_3 + x_2x_3}{x_1x_2}, \frac{x_2 + 1}{x_1}, \frac{x_1 x_2 + x_1 + x_3 + x_2 x_3}{x_1x_2x_3}\right\}.
	\end{equation*}
	Somehow, some miraculous cancelation happened.
	Note that the expression $\frac{x_2 + 1}{x_2}$ already appeared previously.
	If we instead mutate in direction 1, we get
	\begin{equation*}
		\mu_{2131}(Q) =
		\begin{tikzcd}
			1 \rar[leftarrow] \ar[rr,leftarrow, bend right] & 2 & 3
		\end{tikzcd},
	\end{equation*}
	\begin{equation*}
		\mu_{2131}(\bx) = \left\{\frac{x_1 + x_3 + x_1x_2}{x_2x_3}, \frac{x_1 + x_3}{x_2}, \frac{x_1 x_2 + x_1 + x_3 + x_2 x_3}{x_1x_2x_3}\right\}.
	\end{equation*}
	This still introduces a new expression.
	Interestingly, these are all the possible expressions we can obtain!
	If we now mutate in, say, direction 3, we would get as cluster
	\begin{equation*}
		\mu_{21313} = \left\{\frac{x_1 + x_3 + x_1x_2}{x_2x_3}, \frac{x_1 + x_3}{x_2}, x_1 \right\}.
	\end{equation*}
	This is again a dramatic cancelation. One can check manually
	that no mutations introduce new cluster variables.
\end{example}

From these examples we can observe a few things:
\begin{enumerate}
	\item Even though a sequence of mutations might result in the same quiver, the corresponding
	      cluster variables might be different.
	\item For some quivers, the number of obtainable cluster variables is finite.
	\item Independent of the quiver, all the cluster variables are Laurent polynomials in the
	      original cluster variables.
	\item The Laurent polynomials have coefficients in the positive integers.
\end{enumerate}

To have the correct setting to explain the above observations, we must introduce the
notion of a \emph{cluster algebra}\index{algebra!cluster}. From
\cref{lem:mutation_involution} it follows that the process of applying mutations is
invertible. This means that we get a well-defined notion of
\emph{mutation-equivalence}\index{mutation!-equivalence} of seeds. Two seeds are
equivalent if one can be obtained from the other through a sequence of mutations.
Choose some initial seed $(Q, \tbx)$, and write $\mathbf{c} = \tbx \setminus \bx =
	\{x_i \in \tbx' \mid i \in \frz\}$.
\begin{definition}
	The \emph{cluster algebra} $\mcA (Q, \tbx)$ is the subalgebra of $\mcF$ generated by
	$\mathbf{c}^\pm$ and all cluster variables $\bx'$ for seeds $(Q', \tbx')$
	mutation-equivalent to the initial seed $(Q, \tbx)$.
\end{definition}
\begin{remark}
	Note that
	$\mathbf{c}$ is the same for any two mutation-equivalent seeds, so the definition of
	the cluster algebra only depends on the equivalence class of a seed.
\end{remark}

The first two observations are about two notions of ``finiteness'' of cluster algebras.
When there are only finitely many mutation-equivalent quivers, we say that the cluster
algebra is \emph{mutation-finite}\index{mutation!-finite}. When there are only finitely
many cluster variables, we say that the cluster algebra is
\emph{cluster-finite}\index{cluster!-finite}\footnote{It is also common to say that a
	cluster algebra is of finite type instead of calling it cluster-finite.}.

Mutation-finite cluster algebras need not be cluster-finite. For example, the Markov
quiver is mutation-finite (the mutation class consists of one element), but has
infinitely many cluster variables. The inverse implication is true, any cluster-finite
cluster algebra is automatically also mutation-finite. Indeed, suppose that there are
finitely many cluster variables, but infinitely many distinct quivers. By the
pigeonhole principle, there is some cluster which appears in infinitely many seeds.
Since there are only finitely many variables in the cluster, one of them has to appear
in an infinite number of exchange rules, but that leads to infinitely many new cluster
variables.

Remarkably, it is possible to classify the cluster- and mutation-finite cluster
algebras. To state the classification more precisely, the following lemma is useful:
\begin{lemma}
	Let $Q$ be an unoriented finite tree. Then any two orientations of $Q$ are mutation-equivalent through mutations at only sources and sinks. Recall that a source is a vertex such that all arrows incident to the vertex point away from the vertex, while a sink is a vertex such that all incident arrows point to the vertex.
\end{lemma}

\begin{proof}
	We prove this by induction on the number of vertices in $Q$. When $Q$ consists of just a single vertex, there is nothing to prove. Now assume that the statement holds for any tree with $n$ vertices, and let $Q$ be an unoriented tree with $n+1$ vertices. Fix an orientation of $Q$, and let $Q'$ be another orientation of $Q$. Since $Q$ is a tree, it has a leaf $v$, (a vertex of degree 1). Performing a mutation at $v$ only flips the orientation of the single arrow connected to it. Furthermore, it is always a source or a sink.

	Now, consider the subgraph of $Q_v$ obtained by removing $v$ and the arrow connected to
	it. This is a tree with $n$ vertices, and we can hence transform it, by induction, to
	the orientation $Q'_v$ by only mutating at sources and sinks. Write $w$ for the other
	vertex connected to $v$ in $Q$. Applying the same mutations to $Q$ instead of $Q_v$
	would yield the desired orientation for all the arrows, except possibly the arrow
	between $v$ and $w$. This can be fixed by mutating a final time at $v$ if necessary.

	There is one other subtlety. When applying the mutations to $Q$ instead of $Q_v$, it is
	possible that $w$ would no longer be a source or sink due to the extra arrow between
	$v$ and $w$. This is easily amended by applying a mutation at $v$ whenever the
	orientation of the arrow between $v$ and $w$ is wrong.
\end{proof}
Some converse of this theorem is also true, but the proof is no longer purely combinatorial, and requires advanced techniques:
\begin{theorem}[\cite{CalderoKeller2006TriangulatedCat}]
	Let $Q$ and $Q'$ be two acyclic quivers (without oriented cycles) which are mutation-equivalent. Then $Q$ can be transformed into $Q'$ via a sequence of mutations at sources and sinks.
\end{theorem}
This implies in particular that if an acyclic quiver is mutation-equivalent to an
orientation of a tree, then it must be an orientation of the same tree. So, two
non-isomorphic trees are never mutation-equivalent to each other.

We will state the classification theorem without proof, since it is interesting, but
not very relevant for the rest of the thesis. A complete proof can be found in, e.g.,
\cite{FominZelevinsky2003CAFin} or \cite{FominWilliams2021IntroductionCA_4-5}.
\begin{theorem}[Fomin--Zelevinsky]
	A cluster algebra $\mcA (Q, \tbx)$ is cluster-finite if and only if $Q$ is
	mutation-equivalent to a simply-laced (of type $ADE$) Dynkin diagram\footnote{When matrices are used instead of quivers (see later), then all Dynkin diagrams appear.}. In this case there is a bijective correspondence between the cluster variables and the almost positive roots $\Phi_{\geq -1}$, given by
	\begin{equation*}
		\alpha \leftrightarrow \frac{P_\alpha (\tbx)}{x^\alpha},
	\end{equation*}
	where $P_\alpha (\bx)$ is a polynomial in $\tbx$.
\end{theorem}

To understand the correspondence with the almost positive roots a bit better, we return
to the $A_3$ quiver. We obtained a total of $9 = 3 + 6$ cluster variables:
\begin{align*}
	 & x_1, x_2, x_3,                                                                                               \\
	 & \frac{x_2 + 1}{x_1}, \frac{x_1 + x_3}{x_2}, \frac{x_2 + 1}{x_3},                                             \\
	 & \frac{x_1+x_3+x_2x_3}{x_1x_2}, \frac{x_1+x_3+x_1x_2}{x_2x_3}, \frac{x_1x_2 + x_1 + x_3 + x_2x_3}{x_1x_2x_3}.
\end{align*}
We can write the positive roots of $A_3$ as $\{\alpha_1, \alpha_2, \alpha_3, \alpha_1 + \alpha_2, \alpha_2 + \alpha_3, \alpha_1 + \alpha_2 + \alpha_3\}$ for some choice of simple roots $\alpha_1, \alpha_2, \alpha_3$. The simple roots correspond to the second row of cluster variables, while the other positive roots correspond to the last row by looking at the exponents in the denominator. In the theorem, one also includes the additive inverses of the simple roots, i.e., $-\alpha_1, -\alpha_2, -\alpha_3$, such that the original cluster variables are counted as well.

We already saw that cluster-finite cluster algebras are mutation-finite. Beyond those,
which other cluster algebras are mutation-finite? It turns out that, other than a few
exceptions, the only other ones are those originating from triangulations of surfaces
with boundary and punctures (which we will discuss later)
(\cite{FeliksonShapiroTumarkin2012SkewSCA}). If one considers a more general version of
cluster algebras, then the classification stays roughly the same
(\cite{FeliksonPavel2023cluster}). An example of a quiver that is not mutation-finite,
is the following:
\begin{equation*}
	Q =
	\begin{tikzcd}[sep = small]
		& 3 & \\
		1 \urar &&2 \ular \\
		& 4 \ular \ar[uu] \urar
	\end{tikzcd}
\end{equation*}
%
After applying in order, the mutations at the vertices $1,2,3$ and 4, one obtains the
quivers
\begin{equation*}
	\mu_{1234}(Q) =
	\begin{tikzcd}[sep = small]
		& 3 & \\
		1 \urar[leftarrow, "5"] &&2 \ular[leftarrow, "5"'] \\
		& 4 \ular[leftarrow, "2"] \ar[uu, "3"] \urar[leftarrow, "2"']
	\end{tikzcd}
	,\quad \mu_{12341234}(Q) =
	\begin{tikzcd}[sep = small]
		& 3 & \\
		1 \urar["1406"] &&2 \ular["1406"'] \\
		& 4 \ular["83"] \ar[uu, "17"] \urar["83"']
	\end{tikzcd}
\end{equation*}
%
Repeating the same mutations will only increase the amount of arrows. \medskip

Let us now look at the third and fourth observation that we made from the examples:
that all the cluster variables are Laurent polynomials with positive integer
coefficients, in the variables of the initial seed. At a first glance it might seem
obvious that all the coefficients would be positive, since the exchange rule does not
involve any subtractions. The subtlety comes from the cancelations that occur to reduce
the fractions to Laurent polynomials. For example, the fraction $\frac{x^3 +
		y^3}{x(x+y)}$ simplifies to $\frac{x^2 - xy + y^2}{x}$. We now formulate the much
alluded-to \emph{Laurent phenomenon}.
\begin{theorem}[Laurent Phenomenon\index{Laurent!-phenomenon}]\label{thm:laurent_phenomenon}
	Let $\mcA (Q, \tbx)$ be a cluster algebra. Each of the cluster variables can be written as a Laurent polynomial in $\tbx$ with integer coefficients.
\end{theorem}
This theorem was proven already by Fomin and Zelevinsky in their paper introducing cluster algebras(\cite[Theorem 3.1]{FominZelevinsky2002CAF}). They conjectured that all the coefficients would be positive. This was first proven by Lee and Schiffler for the types of cluster algebras coming from quivers (\cite{LeeSchiffler2015PositivityCA}). Later, in a groundbreaking paper, Gross, Hacking, Keel and Kontsevich proved the more general case as well as a number of other open conjectures (\cite{GrossHackingKeelKontsevich2018CanonicalBCA}).

\begin{proof}[Proof of \cref{thm:laurent_phenomenon}]
	TODO
\end{proof}

We finish this section by revisiting the examples from the first section. TODO

\subsection{The Grassmannian}
Definition of Grassmannian. Plucker coordinates, algebra relations. Special case of
$k=2$. Correspondence with triangulations.
\subsection{Triangulations of surfaces}
Explain how to generalize to marked surfaces with punctures.
\section{Quantum cluster algebras}

\subsection{Quantum tori}

Some of the basic background needed on quantum tori, and rational actions.

\subsection{Quantum cluster algebras}

Toric frames, quantum seeds and mutations. Quantum Laurent phenomenon.

\subsection{Quantum Grassmannians}
???

\subsection{CGL extensions}

\textbf{Motivate section as a generic way to produce quantum cluster algebras.}

In this section we will look at a purely algebraic method of placing a quantum cluster
algebra structure on certain class of algebras as first presented in
\cite{GoodearlYakimov2017QCA}. Not only do these have the structure of a quantum
cluster algebra, they also equal the corresponding upper cluster algebra. Along the way
we will provide plenty of examples, to make it clear how the results can be applied in
practice.

\textbf{What is Ore extension. Example of Weyl algebra.}
\begin{definition}
	Let $R$ be a ring with unit, $\sigma \colon R \to R$ be a ring endomorphism and
	$\delta \colon R \to R$ a $\sigma$-\emph{derivation}\index{ring!-derivation}, i.e.,
	$\delta$ is a group homomorphism $(R, +) \to (R, +)$ such that $\delta (r s) =
		\sigma(r)\delta(s) + \delta(r) s$. Then we write $R[x;\sigma, \delta]$ for the ring generated by $R$ and $x$ with the additional relation that
	\begin{equation*}
		x r = \sigma(r) x + \delta(r)
	\end{equation*}
	%
	for all $r \in R$. We call $R[x;\sigma, \delta]$ an \emph{Ore extension}\index{Ore
		extension} or \emph{skew polynomial ring}\index{ring!skew polynomial}. The conditions
	on $\sigma$ and $\delta$ ensure that the multiplication is well-defined.
\end{definition}
%
In our case we will be working with algebras $R$ over some field $\bbK$. The
construction of an Ore extension yields a $\bbK$-algebra, provided that $\sigma$ and
$\delta$ are also $\bbK$-linear.
\begin{example}
	Let $A_1$ be the $\bbK$-algebra generated by two variables $x$ and $y$ such that $yx =
		xy + 1$. This algebra is known as the \emph{Weyl algebra}\index{algebra!Weyl}. It can
	also be viewed as an Ore extension $\bbK[x][y; \id, \partial_x]$:
	\begin{itemize}
		\item The base algebra is the polynomial ring $\bbK[x]$.
		\item The algebra endomorphism $\sigma$ is the identity.
		\item The $\sigma$-derivation $\delta$ is the formal derivative with respect to $x$:
		      \begin{equation*}
			      \partial_x \left(\sum_{i=0}^n a_i x^i \right) = \sum_{i=1}^{n} a_i i x^{i-1}.
		      \end{equation*}
		      %
		      That $\partial_x$ is a derivation follows from the ordinary product rule for derivatives.
	\end{itemize}
\end{example}

\textbf{What is rational action of a torus.}

We borrow some definitions from \cite{GoodearlBrown2002LecturesAQC}. Let $\mcH$ be a
group, and $A$ a $\bbK$-algebra. We say that $\mcH$ \emph{acts on $A$ by
	automorphisms}\index{action!by automorphisms} if for every $h \in \mcH$, the map $A \to
	A \colon x \mapsto h \cdot x$ is a $\bbK$-algebra automorphism. A nonzero element $u
	\in A$ is called an \emph{$\mcH$-eigenvector}\index{H@$\mcH$!-eigenvector} if $\mcH
	\cdot u \subseteq \bbK u$. So, for each $h \in \mcH$ there exists some $\lambda_h \in
	\bbK$ such that $h \cdot u = \lambda_h u$. Since $\mcH$ acts by automorphisms,
$\lambda_h \neq 0$ for all $h \in \mcH$. So, we get a group homomorphism $\chi_u \colon
	\mcH \to \bbK^\times$ given by $\chi_u(h) = \lambda_h$. We call $\chi_u$ the
\emph{$\mcH$-eigenvalue}\index{H@$\mcH$!-eigenvalue} of $u$. Associated to each
$\mcH$-eigenvalue is its \emph{$\mcH$-eigenspace}\index{H@$\mcH$!-eigenspace}
\begin{equation*}
	A_\chi = \{u \in A \mid h \cdot x = \chi(h)x \forall h \in \mcH \}.
\end{equation*}
%
Finally, we say that the action is \emph{semisimple}\index{action!semisimple} if $A$ is
the direct sum of its $\mcH$-eigenspaces.

Now, let $\mcH$ be a \emph{$\bbK$-torus}\index{torus}, that is, a group of the form
$(\bbK^\times)^r$. By identifying $\mcH$ with the affine variety $\{(x_1, \dots, x_r,
	y) \in \bbK^{r+1} | x_1 \dots x_r y = 1\}$, we can view it as an algebraic group.
Assume that $\mcH$ acts on a $\bbK$-algebra $A$ by $\bbK$-algebra automorphisms. Then
we say that the action of $\mcH$ on $A$ is \emph{rational}\index{action!rational} if it
is semisimple, and all the corresponding $\mcH$-eigenvalues are morphisms of affine
varieties.

Write
\begin{equation*}
	X(\mcH) = \{\chi \in \Hom(\mcH, \bbK^\times) \mid \chi \text{ is a morphism of algebraic varieties}\},
\end{equation*}
%
for the character group\index{group!character} of $\mcH$. Then a rational action is the
same as an $X(\mcH)$-grading\index{grading} of $A$. Indeed, if we have a rational
action on $A$, then we can write
\begin{equation*}
	A = \bigoplus_{\chi \in X(\mcH)} A_\chi,
\end{equation*}
which is graded because for $a \in A_\chi, b \in A_{\chi'}$ and all $h \in \mcH$:
\begin{align*}
	h \cdot (a b) = (h\cdot a)(h\cdot b)= \chi(h)a \chi'(h)b = (\chi \chi')(h)ab,
\end{align*}
so that $ab \in A_{\chi \chi'}$. Conversely, if
\begin{equation*}
	A = \bigoplus_{g \in X(\mcH)} A_g
\end{equation*}
is a grading, then we get a rational action through
\begin{equation*}
	h \cdot x = h \cdot \left(\sum_{g \in X(\mcH)} x_g \right) = \sum_{g \in X(\mcH)} g(h)x.
\end{equation*}
%
Under this correspondence, the $\mcH$-eigenvectors are precisely the nonzero
homogeneous\index{homogeneous} elements under the grading.

\textbf{TODO: Examples}.

\textbf{Def CGL extension. Example of matrices, and Heisenberg algebra.}

The combination of a rational action by a torus and iterated Ore extensions gives rise
to the following definition:
\begin{definition}[\protect{\cite[Definition 3.3]{GoodearlYakimov2017QCA}}]
	An iterated Ore extension
	\begin{equation*}
		R = \bbK[x_1][x_2; \sigma_2, \delta_2]\cdots [x_N; \sigma_N, \delta_N]
	\end{equation*}
	is called a \emph{CGL extension}\index{CGL extension} if it is equipped with a rational action of a $\bbK$-torus $\mcH$ by $\bbK$-algebra automorphisms such that
	\begin{enumerate}
		\item\label{itm:x_i-eigenvectors} The elements $x_1, \dots, x_N$ are $\mcH$-eigenvectors.
		\item For every $k\in [2, N]$, $\delta_k$ is \emph{locally
			      nilpotent}\index{nilpotent!locally}, i.e., for all $r \in R_{k-1}$, there exists some
		      $n \in \bbZ_{>0}$ such that $\delta_k^n (r) = 0$. Here, $R_{k-1}$ denotes the
		      subalgebra consisting of only the first $k-1$ extensions:
		      \begin{equation*}
			      R_{k-1} = \bbK[x_1][x_2; \sigma_2, \delta_2]\cdots[x_{k-1};\sigma_{k-1}, \delta_{k-1}].
		      \end{equation*}
		      %
		      \item\label{itm:sigma_k-is-h_k} For every $k \in [1, N]$, there exists $h_k \in \mcH$ such that $\sigma_k$ is given by the action of $h_k$ on $R_{k-1}$ and the $h_k$-eigenvalue of $x_k$, is not a root of unity.
	\end{enumerate}
\end{definition}

We will write $\lambda_k$ for the $h_k$-eigenvalue of $x_k$, i.e., $h_k \cdot x_k =
	\lambda_k$. For $1 \leq j < k \leq N$, we have $\sigma_k (x_j) = h_k \cdot x_j =
	\lambda_{kj} x_j$ for some $\lambda_{kj} \in \bbK^\times$ using conditions
\labelcref{itm:x_i-eigenvectors,itm:sigma_k-is-h_k}. We can complete this to a
multiplicatively skew-symmetric matrix $\boldsymbol{\lambda}= (\lambda_{kj}) \in
	M_N(\bbK^\times)$ by setting $\lambda_{kk} = 1$ and $\lambda_{jk} = \lambda_{kj}\inv$
for $1 \leq j < k \leq N$.

\textbf{Homogeneous prime elements.}

\textbf{(Key parts of) proof of main theorem from \cite{GoodearlYakimov2017QCA}.}

% \section{Some definitions}

% We start with the non-quantized version of cluster algebras, introduced in
% \cite{FominZelevinsky2002CAF}. We won't take the most general definition, since that
% doesn't carry over as nicely to the quantized version.

% \subsection{Notation}

% Some of the notation that we will use throughout this paper. Let $[a,b] = \{a, a+1,
% 	\dots, b\}$ for integers $a,b \in \bbZ$, where $[a,b] = \emptyset$ if $a > b$. Fix an
% integer $N$, and a subset $\ex \subseteq [1, N]$ of size $n$. The elements of $\ex$
% will be called the \emph{exchangeable} indices. Let $\mcF = \bbQ(Y_1, \dots, Y_N)$, be
% the field of rational functions over $\bbQ$. Boldface letters will be used to denote
% vectors, matrices, or clusters.

% \subsection{Classical cluster algebras}

% Before giving the definition of a cluster algebra, we need to define what seeds and
% seed mutations are.
% \begin{definition}[\cite{BerensteinZelevinsky2005QCA}]
% 	A \emph{seed} is a pair $(\tilde{\mathbf{x}}, \tilde{B})$ such that
% 	\begin{enumerate}
% 		\item $\tilde{\mathbf{x}}$ is a \emph{free generating set} of $\mcF$.
% 		      So, $\tilde{\mathbf{x}}$ is a set of $N$ elements $x_1, \dots, x_n \in \mcF$ that are algebraically independent, and generate $\mcF$.
% 		\item $\tilde{B}$ is an $N \times n$ matrix over $\bbZ$ with columns labeled by the exchangeable
% 		      indices $\ex$. Let $B$ be the $n \times n$ submatrix
% 		      of $\tilde{B}$ consisting of all the rows with index in $\ex$.
% 		      We call $B$ the \emph{principal part} of $\tilde{B}$, and require that it is \emph{skew-symmetrizable}.
% 		      This means that there exists a diagonal matrix $D$ with positive entries
% 		      such that $D\inv B D = - B^T$ i.e., $BD$ is skew-symmetric.
% 	\end{enumerate}
% \end{definition}

% Looking only at the exchangeable indices, we get the \emph{cluster} $\mathbf{x} = \{x_i
% 	\mid i \in \ex \} \subseteq \tilde{\mathbf{x}}$.
% \begin{definition}
% 	Let $(\tilde{\mathbf{x}}, \tilde{B})$ be a seed.
% 	The \emph{seed mutation} in direction $k \in \ex$
% 	produces a new seed $\mu_k(\tilde{\mathbf{x}}, \tB) = (\tilde{\bx}', \tB')$, where:
% 	\begin{itemize}
% 		\item $\tbx' = (\tbx \setminus \{x_k\}) \cup \{x_k'\}$,
% 		      with $x_k' \in \mcF$ determined by the \emph{exchange relation}:
% 		      \begin{equation}
% 			      \label{eq:exchange_relation}
% 			      x_kx_k' = \prod_{\substack{i \in [1,N] \\ b_{ik} > 0}}x_i^{b_{ik}} + \prod_{\substack{i \in [1, N] \\ b_{ik} < 0}}x_i^{-b_{ik}}.
% 		      \end{equation}
% 		\item $\tB'$ is given by the formula:
% 		      \begin{equation}
% 			      \label{eq:matrix_mutation}
% 			      b'_{ij} =
% 			      \begin{cases}
% 				      -b_{ij}                                            & \text{ if } i=k \text{ or } j=k \\
% 				      b_{ij} + \frac{|b_{ik}|b_{kj} + b_{ik}|b_{kj}|}{2} & \text{ otherwise}
% 			      \end{cases}
% 			      .
% 		      \end{equation}
% 	\end{itemize}
% \end{definition}

% \begin{remark}
% 	These formulas seem a bit random at first sight,
% 	but have a nice interpretation in the language of quivers.
% 	Assume that $B$ is skew-symmetric,
% 	and let $Q$ be the directed graph on $N$ vertices with $b_{ij}$ edges
% 	from $i$ to $j$ if $j \in \ex$. If $b_{ij}$ is negative,
% 	the edges have the opposite orientation.
% 	Now, define the mutation of $Q$ at vertex $k$ as follows:
% 	\begin{itemize}
% 		\item For every edge connected to $k$, flip its orientation.
% 		\item For every pair of edges $i\to k$ and $k\to j$, create an edge $i \to j$. Then
% 		      ``cancel'' any pair of edges between $i$ and $j$ with opposite orientation.
% 	\end{itemize}
% 	The new matrix representing this graph, will be given precisely by \cref{eq:matrix_mutation}.
% 	Furthermore, the exchange relation (\ref{eq:exchange_relation}) now takes the following form:
% 	\begin{equation*}
% 		x_kx_k' = \prod_{i \to k}x_i + \prod_{k \to j}x_i.
% 	\end{equation*}
% \end{remark}

% \medskip

% With these definitions out of the way we define the \emph{cluster algebra} associated
% to a seed as the subalgebra of $\mcF$ generated by the union of clusters of all seeds
% obtained through (iterative) mutations of the initial seed.

% Instead of proving things now for the classical case, we will jump directly to the
% quantized version to avoid having to prove the same results twice.

% \subsection{Quantum cluster algebras}

% \textbf{TODO: add more notation!}
% We will follow the notation as presented in \cite{GoodearlYakimov2017QCA}.
% Let $\bbK$ be any field.
% As a first step, we move from $\bbQ(Y_1, \dots, Y_N)$ to
% the \emph{quantum torus}
% \begin{equation*}
% 	\mcT_{\mathbf r} =
% 	\frac{\bbK\langle Y_1^{\pm 1}, \dots, Y_N^{\pm 1} \rangle}{\langle Y_iY_j = r_{ij}Y_jY_i \rangle},
% \end{equation*}
% where $\mathbf{r} \in M_N(\bbK^*)$ is a multiplicatively skew-symmetric matrix i.e.,
% $r_{ij} = r_{ji}\inv, r_{ii} = 1$.
% Associated to any such matrix, is a skew-symmetric bicharacter
% \footnote{With a bicharacter we mean a map from a direct product,
% 	such that each of the component maps is a group character.}:
% \begin{equation*}
% 	\Omega_{\mathbf{r}} \colon \bbZ^N \times \bbZ^N \to \bbK^* \colon
% 	\Omega_{\mathbf{r}}(e_i, e_j) = r_{ij}.
% \end{equation*}

% To prevent formulas from having $\frac{1}{2}$'s in the exponents, we will work with the
% \emph{quantum torus}\footnote{ The reason it's called a quantum torus is the following:
% 	it is a quantization of the coordinate algebra of the torus $(\bbK^{*})^N$. }
% $\mcT_{\mathbf{r}^{\cdot 2}}$, where
% \begin{equation*}
% 	\mathbf{r}^{\cdot 2} \coloneq (r_{ij}^2) \in M_N(\bbK^*).
% \end{equation*}
% This torus has a $\bbK$-basis consisting of elements
% \begin{equation*}
% 	Y^{(f)} \coloneq \mcS_{\mathbf{r}}(f)Y^f = \mcS_{\mathbf{r}}(f)Y_1^{m_1}\dots Y_N^{m_N}
% 	\text{ for } f = (m_1, \dots, m_n)^T \in \bbZ^N,
% \end{equation*}
% where
% \begin{equation*}
% 	\mcS_{\mathbf{r}}(f) \coloneq \prod_{i < j}r_{ij}^{-m_im_j}.
% \end{equation*}
% Then $Y^{(e_k)} = Y_k$ for all $k \in [1, N]$ as
% \begin{align*}
% 	Y^{(e_k)}
% 	 & = \mcS_{\mathbf{r}}(e_k)Y^{e_k}                      \\
% 	 & = (\prod_{i < j}r_{ij}^{-\delta_{ik}\delta{jk}} )Y_k \\
% 	 & = (\prod_{i < j}r_{ij}^0 )Y_k                        \\
% 	 & = Y_K.
% \end{align*}
% Additionally, we have the following multiplication rule for $f,g \in \bbZ^N$:
% \begin{equation*}
% 	Y^{(f)}Y^{(g)} = \Omega_{\mathbf{r}}(f,g)Y^{(f+g)}.
% \end{equation*}
% Indeed,
% \begin{align*}
% 	Y^{(f)}Y^{(g)}
% 	 & = \mcS_{\mathbf{r}}(f)Y^f\mcS_{\mathbf{r}}(g)Y^g                                    \\
% 	 & = (\prod_{i < j}r_{ij}^{-f_if_j})(\prod_{i}Y_i^{f_i})
% 	(\prod_{i < j}r_{ij}^{-g_ig_j})( \prod_{i}Y_i^{g_i})                                   \\
% 	 & = (\prod_{i < j}r_{ij}^{-f_if_j - g_ig_j})
% 	(\prod_{k}Y_k^{f_k})(\prod_{k}Y_k^{g_k})                                               \\
% 	 & = (\prod_{i < j}r_{ij}^{-f_if_j - g_ig_j})
% 	(\prod_{i < j}r_{ij}^{-2g_if_j})(\prod_{k}Y_k^{f_k + g_k})
% 	 & (Y_i^{f_i} Y_j^{g_j} = r_{ij}^{2f_ig_j}Y_j^{g_j}Y_i^{f_i})                          \\
% 	 & = (\prod_{i < j}r_{ij}^{-(f_if_j +2g_if_j + g_ig_j)})
% 	(\prod_{k}Y_k^{f_k + g_k})                                                             \\
% 	 & = (\prod_{i < j}r_{ij}^{f_ig_j - g_if_j})
% 	(\prod_{i < j}r_{ij}^{-(f_if_j + f_ig_j + g_if_j + f_ig_j)})(\prod_{k}Y_k^{f_k + g_k}) \\
% 	 & = (\prod_{i,j}r_{ij}^{f_ig_j})
% 	(\prod_{i < j}r_{ij}^{-(f_i + g_j)(f_j + g_j)})(\prod_{k}Y_k^{f_k + g_k})              \\
% 	 & = \Omega_{\mathbf{r}}(f,g)Y^{(f + g)}.
% \end{align*}
% The torus $\mcT_{\mathbf{r}^{\cdot 2}}$ with the basis $\{Y^(f) \mid f \in \bbZ^N\}$
% is called the \emph{based quantum torus} associated to the matrix $\mathbf{r}$.

% We now come to the analog of clusters in the quantum setting.
% \begin{definition}
% 	A map $M \colon \bbZ^N \to \mcF$ is called a \emph{toric frame} if there exists
% 	a multiplicatively skew-symmetric matrix $\mathbf{r} \in M_N(\bbK^*)$ such that:
% 	\begin{enumerate}
% 		\item There is an algebra embedding $\varphi \colon \mcT_{\mathbf{r}^{\cdot 2}} \injto \mcF$
% 		      given by $\varphi(Y_i) = M(e_i)$, such that $\mcF =
% 			      \Fract(\varphi(\mcT_{\mathbf{r}^{\cdot 2}}))$.
% 		\item For all $f \in \bbZ^N$, $M(f) = \varphi(Y^{(f)})$.
% 	\end{enumerate}
% \end{definition}
% \begin{remark}
% 	We can always recover the matrix $\mathbf{r}$ from the toric frame $M$,
% 	since
% 	\begin{align*}
% 		r_{ij}
% 		                         & = \Omega_{\mathbf{r}}(e_i, e_j)                    \\
% 		                         & = Y^{(e_i)}Y^{(e_j)}(Y^{(e_i + e_j)})\inv          \\
% 		                         & \Big\Updownarrow                                   \\
% 		r_{ij} = \varphi(r_{ij}) & = \varphi(Y^{(e_i)}Y^{(e_j)}(Y^{(e_i + e_j)})\inv) \\
% 		                         & = M(e_i)M(e_j)M(e_i + e_j)\inv.
% 	\end{align*}
% 	We'll use the notation $\mathbf{r}(M)$ to denote the matrix of the toric frame $M$.
% \end{remark}
% Now, for quantum seeds, we'll need an extra compatibility condition:
% \begin{definition}
% 	A \emph{quantum seed} is a pair $(M, \tB)$ consisting of a toric frame $M$
% 	and an $N \times n$ matrix $B$ over $\bbZ$ such that
% 	\begin{enumerate}
% 		\item The principal part of $\tB$ is skew-symmetrizable.
% 		\item The pair $(\mathbf{r}(M), \tB)$ is \emph{compatible}.
% 	\end{enumerate}
% \end{definition}

% So, what is this extra compatibility? In analogy with \cref{eq:exchange_relation} we
% want to define $\mu_k(M)$ in such a way that $\mu_k(M)(e_j) = M(e_j)$ for $j \neq k$
% and
% \begin{equation*}
% 	M(e_k)\mu_k(M)(e_k) = M([b^k]_+) + M(-[b^k]_-),
% \end{equation*}
% where $b^k$ is the $k$-th column of $B$.
% Bringing $M(e_k)$ to the other side,
% and ignoring eventual symmetrization constants we can then define
% \begin{equation*}
% 	\mu_k(M)(e_k) = M(-e_k + [b^k]_+) + M(-e_k - [b^k]_-).
% \end{equation*}
% Let $\epsilon$ be a sign $\pm 1$. Then we can rewrite the definition as
% \begin{align*}
% 	\mu_k(M)(e_k)
% 	 & = M(-e_k + [b^k]_+) + M(-e_k - [b^k]_-)                                    \\
% 	 & = M(-e_k + [-\epsilon b^k]_+) + M(-e_k - [-\epsilon b^k]_+ + \epsilon b^k) \\
% 	 & = M(E_\epsilon e_k) + M(E_\epsilon(e_k + \epsilon b^k)),
% \end{align*}
% where $E_\epsilon \in \GL_N(\bbZ)$ is the integer matrix with columns:
% \begin{equation*}
% 	E_\epsilon = (e_1, \dots ,e_{k-1}, [-\epsilon b^k]_+ -e_k, e_{k+1}, \dots, e_N).
% \end{equation*}
% Since, $E_\epsilon$ maps the basis $e_1, \dots, e_N$ of $\bbZ^N$ to another basis,
% and $E_\epsilon e_j = e_j$ for all $j \neq k$,
% we can ignore it when checking that $\mu_k(M)$ defines a toric frame.
% In other words,
% we just need that $M' : \bbZ^N \to \mcF$ defines a toric frame, where
% \begin{align*}
% 	M'(e_j) = M(e_j), j\neq k \quad M'(e_k) = M(e_k) + M(e_k + \epsilon b^k).
% \end{align*}
% On the one hand we have
% \begin{align*}
% 	M'(e_k)M'(e_j)
% 	 & = (M(e_k) + M(e_k + \epsilon b^k))M(e_j)                                                                                \\
% 	 & = M(e_j)(\Omega_{\mathbf{r}}(e_k, e_j)^2 M(e_k) + \Omega_{\mathbf{r}}(e_k + \epsilon b^k, e_j)^2 M(e_k + \epsilon b^k)) \\
% 	 & =\Omega_{\mathbf{r}}(e_k, e_j)^2  M(e_j)(M(e_k) + \Omega_{\mathbf{r}}(\epsilon b^k, e_j)^2 M(e_k + \epsilon b^k))       \\
% 	 & =\mathbf{r}_{k,j}^2  M(e_j)(M(e_k) + \Omega_{\mathbf{r}}(b^k, e_j)^{2 \epsilon} M(e_k + \epsilon b^k)),
% \end{align*}
% while $M'$ being a toric frame would imply
% \begin{align*}
% 	M'(e_k)M'(e_j) = (\mathbf{r}'_{k,j})^2 M'(e_j)M'(e_k).
% \end{align*}
% The easiest way to make the two equations compatible,
% is to demand $\mathbf{r}' = \mathbf{r}$,
% and $\Omega_{\mathbf{r}}(b^k, e_j) = 1$ for $j \neq k$.
% \textbf{TODO: is this the only possible choice?}
% This leads to the following definition:
% \begin{definition}
% 	Let $\tilde{\mathbf{t}} \in M_{n \times N}(\bbK^*)$ be the matrix with entries
% 	\begin{equation*}
% 		t_{ij} = \Omega_{\mathbf{r}}(b^i, e_j) = \prod_{l = 1}^N r_{lj}^{b_{li}},
% 	\end{equation*}
% 	for $j \in \mathbf{ex}$ and $j \in [1, N]$.
% 	We say that $B$ and $\mathbf{r}$ are \emph{compatible} if
% 	$t_{ij} = 1$ whenever $i \neq j$,
% 	and all the $t_{ii}$ are \emph{not} roots of unity.
% \end{definition}
% \textbf{TODO: How to explain the root of unity part? Is there a clean way?}

\bibliographystyle{plain}
\bibliography{references.bib}
\printindex
\end{document}
